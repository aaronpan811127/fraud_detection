{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fe4d723a-7abd-4d6a-977e-e9e33aef8539",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "# Model Training Notebook\n",
    "#\n",
    "# This notebook shows an example of a Model Training pipeline using Delta tables.\n",
    "# It is configured and can be executed as the \"Train\" task in the model_training_job workflow defined under\n",
    "# ``fraud_detection/resources/model-workflow-resource.yml``\n",
    "#\n",
    "# Parameters:\n",
    "# * env (required):                 - Environment the notebook is run in (staging, or prod). Defaults to \"staging\".\n",
    "# * training_data_path (required)   - Path to the training data.\n",
    "# * experiment_name (required)      - MLflow experiment name for the training runs. Will be created if it doesn't exist.\n",
    "# * model_name (required)           - Three-level name (<catalog>.<schema>.<model_name>) to register the trained model in Unity Catalog. \n",
    "#  \n",
    "##################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "102657de-e1da-4ce1-b40d-5ecb0d89fc0c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bab5cffc-c6c2-45fa-9497-081b522aaaad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "notebook_path =  '/Workspace/' + os.path.dirname(dbutils.notebook.entry_point.getDbutils().notebook().getContext().notebookPath().get())\n",
    "%cd $notebook_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "139be125-adfe-46a9-8d2a-f6bb3c3d2d4b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install -r ../../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c6be484b-70c8-4518-a511-e1464ebec9b6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c7e4961a-e316-485d-b135-bf5b3c48a76c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks.connect import DatabricksSession\n",
    "from databricks.sdk import WorkspaceClient\n",
    "\n",
    "spark = DatabricksSession.builder.getOrCreate()\n",
    "w = WorkspaceClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fd228652-d7e0-4299-9d17-471dc91d316a",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Get relevant libraries"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np                   # array, vector, matrix calculations\n",
    "import pandas as pd                  # DataFrame handling\n",
    "import xgboost as xgb                # gradient boosting machines (GBMs)\n",
    "import mlflow\n",
    "import os\n",
    "import mlflow.pyfunc\n",
    "import mlflow.spark\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8281e70c-aaf8-4553-ac8d-a16502fa79f7",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": " Notebook arguments"
    }
   },
   "outputs": [],
   "source": [
    "# List of input args needed to run this notebook as a job.\n",
    "# Provide them via DB widgets or notebook arguments.\n",
    "\n",
    "# Notebook Environment\n",
    "w.dbutils.widgets.dropdown(\"env\", \"staging\", [\"dev\",\"staging\", \"prod\"], \"Environment Name\")\n",
    "env = w.dbutils.widgets.get(\"env\")\n",
    "\n",
    "# Path to the Hive-registered Delta table containing the training data.\n",
    "w.dbutils.widgets.text(\n",
    "    \"training_data_path\",\n",
    "    \"/Volumes/aaron_dev/fraud_detection/raw/Fraud_final-1.csv\",\n",
    "    label=\"Path to the training data\",\n",
    ")\n",
    "\n",
    "# MLflow experiment name.\n",
    "w.dbutils.widgets.text(\n",
    "    \"experiment_name\",\n",
    "    \"/dev-fraud_detection-experiment\",\n",
    "    label=\"MLflow experiment name\",\n",
    ")\n",
    "# Unity Catalog registered model name to use for the trained model.\n",
    "w.dbutils.widgets.text(\n",
    "    \"model_name\", \"aaron_dev.fraud_detection.fraud_detection-model\", label=\"Full (Three-Level) Model Name\"\n",
    ")\n",
    "\n",
    "# Unity Catalog result table.\n",
    "w.dbutils.widgets.text(\n",
    "    \"result_table\", \"aaron_dev.fraud_detection.training_result\", label=\"Training Result Table\"\n",
    ")\n",
    "\n",
    "# Unity Catalog training data table\n",
    "w.dbutils.widgets.text(\n",
    "    \"training_table\", \"aaron_dev.fraud_detection.training_input\", label=\"Training Input Table\"\n",
    ")\n",
    "\n",
    "# MLflow tracking server\n",
    "w.dbutils.widgets.text(\n",
    "    \"tracking_uri\", \"databricks\", label=\"MLflow Tracking Server\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a89b4af5-9968-4018-8a6e-ccceee96b30c",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Define input and output variables"
    }
   },
   "outputs": [],
   "source": [
    "input_table_path = w.dbutils.widgets.get(\"training_data_path\")\n",
    "experiment_name = w.dbutils.widgets.get(\"experiment_name\")\n",
    "model_name = w.dbutils.widgets.get(\"model_name\")\n",
    "result_table = w.dbutils.widgets.get(\"result_table\")\n",
    "training_table = w.dbutils.widgets.get(\"training_table\")\n",
    "tracking_uri = w.dbutils.widgets.get(\"tracking_uri\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2f91f9c4-d271-48eb-b74f-2bcf4f1c03e5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%cp Fraud_final-1.csv $input_table_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "08c7a280-00b2-4da8-9628-2a2ea654cafa",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Persist Txn Flat Files to Delta Lake for Audit and Performance"
    }
   },
   "outputs": [],
   "source": [
    "spark.read.option(\"inferSchema\", \"true\") \\\n",
    "          .option(\"header\", \"true\") \\\n",
    "          .option(\"delim\", \",\") \\\n",
    "          .csv(input_table_path) \\\n",
    "          .write \\\n",
    "          .format(\"delta\") \\\n",
    "          .mode(\"overwrite\") \\\n",
    "          .option(\"overwriteSchema\", \"true\") \\\n",
    "          .saveAsTable(training_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1bdd6992-8ddc-40f2-8c92-7a4798215ab6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Let's first define a outline for feature preprocessing and modeling. We will call the respective preprocessing and modeling functions after we have imported out data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "798dcf96-49db-4b20-9019-f84852d071c2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# This scaling code using the simple sklearn out-of-the-box scaler. It's used here for simplicity and re-used inside our PyFunc class\n",
    "def preprocess_data(source_df,\n",
    "                    numeric_columns,\n",
    "                    fitted_scaler):\n",
    "  '''\n",
    "  Subset df with selected columns\n",
    "  Use the fitted scaler to center and scale the numeric columns  \n",
    "  '''\n",
    "  res_df = source_df[numeric_columns].copy()\n",
    "  \n",
    "  ## scale the numeric columns with the pre-built scaler\n",
    "  res_df[numeric_columns] = fitted_scaler.transform(res_df[numeric_columns])\n",
    "  \n",
    "  return res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c95c1107-3bb3-48ee-9500-91cdbd6cad6f",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "PyFunc Wrapper for Fraud Model"
    }
   },
   "outputs": [],
   "source": [
    "class XGBWrapper(mlflow.pyfunc.PythonModel):\n",
    "  '''\n",
    "    XGBClassifier model with embedded pre-processing.\n",
    "    \n",
    "    This class is an MLflow custom python function wrapper around a XGB model.\n",
    "    The wrapper provides data preprocessing so that the model can be applied to input dataframe directly.\n",
    "    :Input: to the model is pandas dataframe\n",
    "    :Output: predicted price for each listing\n",
    "\n",
    "    The model declares current local versions of XGBoost and pillow as dependencies in its\n",
    "    conda environment file.  \n",
    "  '''\n",
    "  def __init__(self,\n",
    "               model,\n",
    "               X,\n",
    "               y,\n",
    "               numeric_columns):\n",
    "    \n",
    "    self.model = model\n",
    "\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(X, y, test_size=0.30, random_state=2019)\n",
    "    self.numeric_columns = numeric_columns\n",
    "    \n",
    "    from sklearn.preprocessing import StandardScaler \n",
    "    #create a scaler for our numeric variables\n",
    "    # only run this on the training dataset and use to scale test set later.\n",
    "    scaler = StandardScaler()\n",
    "    self.fitted_scaler = scaler.fit(self.X_train[self.numeric_columns])\n",
    "    self.X_train_processed = preprocess_data(self.X_train, self.numeric_columns, self.fitted_scaler)\n",
    "    self.X_test_processed  = preprocess_data(self.X_test, self.numeric_columns, self.fitted_scaler)\n",
    "\n",
    "    def _accuracy_metrics(model, X, y):\n",
    "      import sklearn\n",
    "      from sklearn import metrics\n",
    "      y_pred = model.predict_proba(X)[:,1]\n",
    "      fpr, tpr, thresholds = sklearn.metrics.roc_curve(y, y_pred)\n",
    "      self.auc = sklearn.metrics.auc(fpr, tpr)\n",
    "      print(\"Model AUC is:\", self.auc)\n",
    "\n",
    "      return self.auc\n",
    "    \n",
    "    self.auc = _accuracy_metrics(model=self.model, X=self.X_test_processed, y=self.y_test )\n",
    "    \n",
    "    \n",
    "  def predict(self,  model_input):\n",
    "    '''\n",
    "      Generate predictions from the input df \n",
    "      Subset input df with selected columns\n",
    "      Assess the model accuracy\n",
    "      Use the fitted scaler to center and scale the numeric columns  \n",
    "      :param input: pandas.DataFrame with numeric_columns to be scored. The\n",
    "                   columns must has same schema as numeric_columns of X_train\n",
    "     :return: numpy 1-d array as fraud probabilities \n",
    "\n",
    "    '''\n",
    "    input_processed = self._preprocess_data(X=model_input, numeric_columns=self.numeric_columns, fitted_scaler=self.fitted_scaler )\n",
    "    return pd.DataFrame(self.model.predict_proba(input_processed)[:,1], columns=['predicted'])\n",
    "\n",
    "  \n",
    "  def _preprocess_data(self,\n",
    "                      X,\n",
    "                      numeric_columns,\n",
    "                      fitted_scaler):\n",
    "    res_df = preprocess_data(X, numeric_columns, fitted_scaler)\n",
    "    self._df = res_df\n",
    "    \n",
    "    return res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3b058300-b708-459e-8648-f75de8cb3fef",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Create XGBoost Classifier Model Fit Method - Return Probability and XGB Model"
    }
   },
   "outputs": [],
   "source": [
    "# Our fit method will be used within our MLflow model training experiment run\n",
    "# The AUROC metric is chosen here \n",
    "def fit(X, y):\n",
    "  \"\"\"\n",
    "   :return: dict with fields 'loss' (scalar loss) and 'model' fitted model instance\n",
    "  \"\"\"\n",
    "  import xgboost\n",
    "  from xgboost import XGBClassifier\n",
    "  from sklearn.model_selection import cross_val_score\n",
    "  \n",
    "  _model =  XGBClassifier(learning_rate=0.3,\n",
    "                          gamma=5,\n",
    "                          max_depth=8,\n",
    "                          n_estimators=15,\n",
    "                          min_child_weight = 9, objective='binary:logistic')\n",
    "\n",
    "  xgb_model = _model.fit(X, y)\n",
    "  \n",
    "  score = -cross_val_score(_model, X, y, scoring='roc_auc').mean()\n",
    "  \n",
    "  return {'loss': score, 'model': xgb_model}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "10fb4297-5c51-458b-b817-82b3efe12b76",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Our input dataset has several fields which will be used for rule based modeling and machine learning. In this notebook we will rely on our machine learning model to identify important features that are effective at predicting fraud. Let's take a look into descriptions of these features to understand our downstream modeling and interpretability results.\n",
    "<br>\n",
    "<br>\n",
    "* LAST_ADR_CHNG_DUR     - Duration in days since the last address change on the account.\n",
    "<br>\n",
    "* AVG_DLY_AUTHZN_AMT    - The average daily authorization amount on the plastic since the day of first use.\n",
    "<br>\n",
    "* DISTANCE_FROM_HOME\t  - Approximate distance of customer's home from merchant.\n",
    "<br>\n",
    "* HOME_PHN_NUM_CHNG_DUR - Duration in days since the home phone number was changed on the account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1c010317-a849-4d3d-860c-ae8c9a884366",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Read Delta Lake for Transactions"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import * \n",
    "\n",
    "import cloudpickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "df = spark.read.table(training_table) \n",
    "\n",
    "data = df.toPandas()\n",
    "data = data.drop(columns=['AUTH_ID', 'ACCT_ID_TOKEN'])\n",
    "numeric_columns = data.columns.to_list()\n",
    "numeric_columns.remove('FRD_IND')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "907d7a75-61e3-48bf-8d66-8ed57d1c109b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "conda_env = mlflow.pyfunc.get_default_conda_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4d022c20-4ddf-4f40-a5eb-43a5cf15cca7",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Add xgboost and sklearn to be used in the Docker environment for serving later on"
    }
   },
   "outputs": [],
   "source": [
    "conda_env = mlflow.pyfunc.get_default_conda_env()\n",
    "conda_env['dependencies'][2]['pip'] += [f'xgboost=={xgb.__version__}']\n",
    "conda_env['dependencies'][2]['pip'] += [f'scikit-learn=={sklearn.__version__}']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2b3ebb89-7e17-46ca-a2a6-c10ef8205a01",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": " Set experiment"
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "mlflow.set_experiment(experiment_name)\n",
    "mlflow.set_registry_uri('databricks-uc')\n",
    "mlflow.set_tracking_uri(tracking_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4e6d6eb3-dc2f-4725-ba9d-41b4a88e0866",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "MLFlow Tracking and PyFunc Model Saving"
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from mlflow.models import infer_signature\n",
    "\n",
    "# useremail = w.dbutils.notebook.entry_point.getDbutils().notebook().getContext().userName().get()\n",
    "# experiment_name = f\"/Users/{useremail}/dff_orchestrator\"\n",
    "mlflow.set_experiment(experiment_name) \n",
    "model_run_name = 'fraud-xgb-wrapper'\n",
    "\n",
    "with mlflow.start_run(run_name=model_run_name) as run:\n",
    "  mlflow.log_param('Input-data-location', training_table)\n",
    "  from sklearn.model_selection import train_test_split\n",
    "  X_train, X_test, y_train, y_test = train_test_split(data.drop([\"FRD_IND\"], axis=1), data[\"FRD_IND\"], test_size=0.33, random_state=42)\n",
    "\n",
    "  from sklearn.preprocessing import StandardScaler \n",
    "  # create a scaler for our numeric variables\n",
    "  # only run this on the training dataset and use to scale test set later.\n",
    "  scaler = StandardScaler()\n",
    "  fitted_scaler = scaler.fit(X_train[numeric_columns])\n",
    "  X_train_processed = preprocess_data(source_df=X_train, numeric_columns=numeric_columns, fitted_scaler=fitted_scaler )\n",
    "\n",
    "  #train a model and get the loss\n",
    "  train_dict = {}\n",
    "  train_dict = fit(X=X_train_processed, y=y_train)\n",
    "  xgb_model = train_dict['model']\n",
    "  mlflow.log_metric('loss', train_dict['loss'])\n",
    "  \n",
    "  ##------- log pyfunc custom model -------##\n",
    "   # make an instance of the Pyfunc Class\n",
    "  myXGB = XGBWrapper(model = xgb_model,\n",
    "                     X = data[numeric_columns].copy(), \n",
    "                     y = data['FRD_IND'], \n",
    "                     numeric_columns = numeric_columns)\n",
    "  \n",
    "  signature = infer_signature(X_train_processed, myXGB.predict(model_input = X_train_processed))\n",
    "\n",
    "  mlflow.pyfunc.log_model(model_run_name, python_model=myXGB, conda_env=conda_env, signature=signature,registered_model_name=model_name)\n",
    "\n",
    "  mlflow.log_metric('auroc', myXGB.auc)\n",
    "  \n",
    "# programmatically get the latest Run ID\n",
    "runs = mlflow.search_runs(mlflow.get_experiment_by_name(experiment_name).experiment_id)\n",
    "latest_run_id = runs.sort_values('end_time').iloc[-1][\"run_id\"]\n",
    "print('The latest run id: ', latest_run_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "97864c51-12fe-49d0-b338-ceebdbcce1e1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "After running SHAP on model we can see how some of the features such  duration since address change, transaction amount and available cash in the account were proved to be most important. While this is purely machine learning driven approach, we will look at ways to improve customer satisfaction with rule based modeling based vs really totally on ML based approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9c86e7d8-a150-4ece-96e2-8eb00fee5ba9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "X = data[numeric_columns].copy()\n",
    "y = data['FRD_IND']\n",
    "\n",
    "predictions = myXGB.predict( X)\n",
    "predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f83e89be-b980-432a-82d3-cae5372a74f0",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Use SHAP for Model explainability"
    }
   },
   "outputs": [],
   "source": [
    "import shap\n",
    "from pyspark.sql import *\n",
    "explainer = shap.TreeExplainer(xgb_model)\n",
    "shap_values = explainer.shap_values(X, y=y.values)\n",
    "mean_abs_shap = np.absolute(shap_values).mean(axis=0).tolist()\n",
    "display(spark.createDataFrame(sorted(list(zip(mean_abs_shap, X.columns)), reverse=True)[:8], [\"Mean |SHAP|\", \"Column\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f33a0cab-8737-405d-a024-92ad604986b4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "shap_values = explainer.shap_values(X, y=y.values)\n",
    "print(shap_values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2ad134c5-b2d1-4072-a798-9f38afcf9691",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(shap.force_plot(explainer.expected_value, shap_values[0,:], X.iloc[0,:],matplotlib=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ffb2219c-5a53-41ca-8d01-ec7d694dc3e1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "schema = spark.createDataFrame(X).schema\n",
    "df = spark.createDataFrame(pd.DataFrame(shap_values, columns=X.columns)).withColumn(\"id\", monotonically_increasing_id())\n",
    "for col in df.columns:\n",
    "  df = df.withColumnRenamed(col, 'shap_v_' + col)\n",
    "df.createOrReplaceTempView(\"fraud_shap_values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "806880d0-76c7-4656-83df-e3f685366966",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": " Log model and return output."
    }
   },
   "outputs": [],
   "source": [
    "spark.createDataFrame(pd.concat([pd.DataFrame(X, columns=X.columns), pd.DataFrame(predictions, columns=['predicted']), pd.DataFrame(y, columns=['FRD_IND'])], axis=1)).withColumn(\"id\", monotonically_increasing_id()).createOrReplaceTempView(\"txns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c828b69e-fa1c-46e1-9c76-9fe5fed8b1ef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "### Model Result Saving \n",
    "\n",
    "In addition to saving model fraud scores, we want to be able to interactively query SHAP values on each observation also. We will persist these values on each observation so we can query in tabular form using SQL Analytics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0d26a2e2-8239-4e89-95e1-fcebb383917d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"select t.*, \n",
    "       s.*\n",
    "from txns t join fraud_shap_values s \n",
    "on t.id = s.shap_v_id\"\"\").write.format(\"delta\").option('overwriteSchema', 'true').mode('overwrite').saveAsTable(result_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9076361f-0a41-4782-8d51-e241e303bebe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(spark.sql(f'''\n",
    "select case when predicted > 0.5 then 1 else 0 end predicted_Ind, frd_ind, count(1) ct\n",
    "from {result_table}\n",
    "group by case when predicted > 0.5 then 1 else 0 end, frd_ind\n",
    "''')\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "87c932d6-c68e-44d6-b412-3a377005f99f",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Helper function"
    }
   },
   "outputs": [],
   "source": [
    "from mlflow.tracking import MlflowClient\n",
    "import mlflow.pyfunc\n",
    "\n",
    "\n",
    "def get_latest_model_version(model_name):\n",
    "    latest_version = 1\n",
    "    mlflow_client = MlflowClient(tracking_uri=tracking_uri)\n",
    "    for mv in mlflow_client.search_model_versions(f\"name='{model_name}'\"):\n",
    "        version_int = int(mv.version)\n",
    "        if version_int > latest_version:\n",
    "            latest_version = version_int\n",
    "    return latest_version\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "01896686-3b10-4319-92c8-88e56b1c0722",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# The returned model URI is needed by the model deployment notebook.\n",
    "model_version = get_latest_model_version(model_name)\n",
    "print(model_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1d191ac1-d14d-45ee-90c7-1d53d32ffa77",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# The returned model URI is needed by the model deployment notebook.\n",
    "model_version = get_latest_model_version(model_name)\n",
    "model_uri = f\"models:/{model_name}/{model_version}\"\n",
    "w.dbutils.jobs.taskValues.set(\"model_uri\", model_uri)\n",
    "w.dbutils.jobs.taskValues.set(\"model_name\", model_name)\n",
    "w.dbutils.jobs.taskValues.set(\"model_version\", model_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w.dbutils.notebook.exit(model_uri)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": -1,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "Train",
   "widgets": {
    "env": {
     "currentValue": "dev",
     "nuid": "6add9c85-8b0d-4cf6-931c-c4cbb42a894a",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "staging",
      "label": "Environment Name",
      "name": "env",
      "options": {
       "choices": [
        "dev",
        "staging",
        "prod"
       ],
       "fixedDomain": true,
       "multiselect": false,
       "widgetDisplayType": "Dropdown"
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "defaultValue": "staging",
      "label": "Environment Name",
      "name": "env",
      "options": {
       "autoCreated": null,
       "choices": [
        "dev",
        "staging",
        "prod"
       ],
       "widgetType": "dropdown"
      },
      "widgetType": "dropdown"
     }
    },
    "experiment_name": {
     "currentValue": "/dev-fraud_detection-experiment",
     "nuid": "0b186b23-9884-4c1f-9fc5-c2d3066cc463",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "/dev-fraud_detection-experiment",
      "label": "MLflow experiment name",
      "name": "experiment_name",
      "options": {
       "validationRegex": null,
       "widgetDisplayType": "Text"
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "defaultValue": "/dev-fraud_detection-experiment",
      "label": "MLflow experiment name",
      "name": "experiment_name",
      "options": {
       "autoCreated": null,
       "validationRegex": null,
       "widgetType": "text"
      },
      "widgetType": "text"
     }
    },
    "model_name": {
     "currentValue": "aaron_dev.fraud_detection.fraud_detection-model",
     "nuid": "c4412a16-a8ec-4f0d-a62b-ab9841ea500d",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "aaron_dev.fraud_detection.fraud_detection-model",
      "label": "Full (Three-Level) Model Name",
      "name": "model_name",
      "options": {
       "validationRegex": null,
       "widgetDisplayType": "Text"
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "defaultValue": "aaron_dev.fraud_detection.fraud_detection-model",
      "label": "Full (Three-Level) Model Name",
      "name": "model_name",
      "options": {
       "autoCreated": null,
       "validationRegex": null,
       "widgetType": "text"
      },
      "widgetType": "text"
     }
    },
    "result_table": {
     "currentValue": "aaron_dev.fraud_detection.training_result",
     "nuid": "7263484b-7384-4c8f-92f6-cdb5569f6d5c",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "aaron_dev.fraud_detection.training_result",
      "label": "Training Result Table",
      "name": "result_table",
      "options": {
       "validationRegex": null,
       "widgetDisplayType": "Text"
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "defaultValue": "aaron_dev.fraud_detection.training_result",
      "label": "Training Result Table",
      "name": "result_table",
      "options": {
       "autoCreated": null,
       "validationRegex": null,
       "widgetType": "text"
      },
      "widgetType": "text"
     }
    },
    "tracking_uri": {
     "currentValue": "databricks",
     "nuid": "a6a6f3e8-9111-42de-ae9a-a8c16f4a4895",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "databricks",
      "label": "MLflow Tracking Server",
      "name": "tracking_uri",
      "options": {
       "validationRegex": null,
       "widgetDisplayType": "Text"
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "defaultValue": "databricks",
      "label": "MLflow Tracking Server",
      "name": "tracking_uri",
      "options": {
       "autoCreated": false,
       "validationRegex": null,
       "widgetType": "text"
      },
      "widgetType": "text"
     }
    },
    "training_data_path": {
     "currentValue": "/Volumes/aaron_dev/fraud_detection/raw/Fraud_final-1.csv",
     "nuid": "eaab06e5-3931-404c-95bc-6af40128166e",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "/Volumes/aaron_dev/fraud_detection/raw/Fraud_final-1.csv",
      "label": "Path to the training data",
      "name": "training_data_path",
      "options": {
       "validationRegex": null,
       "widgetDisplayType": "Text"
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "defaultValue": "/Volumes/aaron_dev/fraud_detection/raw/Fraud_final-1.csv",
      "label": "Path to the training data",
      "name": "training_data_path",
      "options": {
       "autoCreated": null,
       "validationRegex": null,
       "widgetType": "text"
      },
      "widgetType": "text"
     }
    },
    "training_table": {
     "currentValue": "aaron_dev.fraud_detection.training_input",
     "nuid": "e627b381-8f26-4b19-9472-da2d00c9186f",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "aaron_dev.fraud_detection.training_input",
      "label": "Training Input Table",
      "name": "training_table",
      "options": {
       "validationRegex": null,
       "widgetDisplayType": "Text"
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "defaultValue": "aaron_dev.fraud_detection.training_input",
      "label": "Training Input Table",
      "name": "training_table",
      "options": {
       "autoCreated": null,
       "validationRegex": null,
       "widgetType": "text"
      },
      "widgetType": "text"
     }
    }
   }
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
